{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227, 50, 50, 3) float64\n",
      "(227,) int32\n",
      "Train on 204 samples, validate on 23 samples\n",
      "Epoch 1/100\n",
      "204/204 [==============================] - 1s 7ms/sample - loss: 1.2442 - accuracy: 0.5098 - val_loss: 0.6832 - val_accuracy: 0.6957\n",
      "Epoch 2/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.6849 - accuracy: 0.6569 - val_loss: 0.6309 - val_accuracy: 0.6957\n",
      "Epoch 3/100\n",
      "204/204 [==============================] - 1s 4ms/sample - loss: 0.6516 - accuracy: 0.6569 - val_loss: 0.6133 - val_accuracy: 0.6957\n",
      "Epoch 4/100\n",
      "204/204 [==============================] - 1s 4ms/sample - loss: 0.6589 - accuracy: 0.6569 - val_loss: 0.6203 - val_accuracy: 0.6957\n",
      "Epoch 5/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.6420 - accuracy: 0.6569 - val_loss: 0.6097 - val_accuracy: 0.6957\n",
      "Epoch 6/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.6412 - accuracy: 0.6569 - val_loss: 0.6110 - val_accuracy: 0.6957\n",
      "Epoch 7/100\n",
      "204/204 [==============================] - 1s 4ms/sample - loss: 0.6369 - accuracy: 0.6569 - val_loss: 0.6017 - val_accuracy: 0.6957\n",
      "Epoch 8/100\n",
      "204/204 [==============================] - 1s 4ms/sample - loss: 0.6423 - accuracy: 0.6569 - val_loss: 0.6113 - val_accuracy: 0.6957\n",
      "Epoch 9/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.6176 - accuracy: 0.6569 - val_loss: 0.5868 - val_accuracy: 0.6957\n",
      "Epoch 10/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.6076 - accuracy: 0.6569 - val_loss: 0.6082 - val_accuracy: 0.6957\n",
      "Epoch 11/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.6006 - accuracy: 0.6667 - val_loss: 0.5474 - val_accuracy: 0.6957\n",
      "Epoch 12/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.5769 - accuracy: 0.7500 - val_loss: 0.6130 - val_accuracy: 0.6957\n",
      "Epoch 13/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.5855 - accuracy: 0.7353 - val_loss: 0.5125 - val_accuracy: 0.6957\n",
      "Epoch 14/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.4907 - accuracy: 0.7794 - val_loss: 0.4616 - val_accuracy: 0.7826\n",
      "Epoch 15/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.4987 - accuracy: 0.6863 - val_loss: 0.4583 - val_accuracy: 0.9565\n",
      "Epoch 16/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.4694 - accuracy: 0.8235 - val_loss: 0.6761 - val_accuracy: 0.6957\n",
      "Epoch 17/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.5846 - accuracy: 0.6667 - val_loss: 0.6094 - val_accuracy: 0.6957\n",
      "Epoch 18/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.5651 - accuracy: 0.7500 - val_loss: 0.7734 - val_accuracy: 0.3043\n",
      "Epoch 19/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.5245 - accuracy: 0.6618 - val_loss: 0.4922 - val_accuracy: 0.7391\n",
      "Epoch 20/100\n",
      "204/204 [==============================] - 1s 7ms/sample - loss: 0.4366 - accuracy: 0.8676 - val_loss: 0.4133 - val_accuracy: 0.7826\n",
      "Epoch 21/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.3633 - accuracy: 0.8824 - val_loss: 0.3807 - val_accuracy: 0.7826\n",
      "Epoch 22/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.3015 - accuracy: 0.9020 - val_loss: 0.3059 - val_accuracy: 0.8696\n",
      "Epoch 23/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.2406 - accuracy: 0.9314 - val_loss: 0.2695 - val_accuracy: 0.8696\n",
      "Epoch 24/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.1985 - accuracy: 0.9559 - val_loss: 0.2550 - val_accuracy: 0.8696\n",
      "Epoch 25/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.2176 - accuracy: 0.9020 - val_loss: 0.2162 - val_accuracy: 0.9565\n",
      "Epoch 26/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.1938 - accuracy: 0.9216 - val_loss: 0.2075 - val_accuracy: 0.9565\n",
      "Epoch 27/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.2073 - accuracy: 0.9118 - val_loss: 0.2069 - val_accuracy: 0.9130\n",
      "Epoch 28/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.1616 - accuracy: 0.9461 - val_loss: 0.1755 - val_accuracy: 0.9565\n",
      "Epoch 29/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.1948 - accuracy: 0.9265 - val_loss: 0.2333 - val_accuracy: 0.8696\n",
      "Epoch 30/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.2153 - accuracy: 0.9265 - val_loss: 0.2329 - val_accuracy: 0.9565\n",
      "Epoch 31/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.3378 - accuracy: 0.8578 - val_loss: 0.2314 - val_accuracy: 0.8696\n",
      "Epoch 32/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.3249 - accuracy: 0.8529 - val_loss: 0.3701 - val_accuracy: 0.7826\n",
      "Epoch 33/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.2864 - accuracy: 0.8676 - val_loss: 0.2308 - val_accuracy: 0.8696\n",
      "Epoch 34/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.1992 - accuracy: 0.9314 - val_loss: 0.2348 - val_accuracy: 0.9565\n",
      "Epoch 35/100\n",
      "204/204 [==============================] - 1s 7ms/sample - loss: 0.1739 - accuracy: 0.9314 - val_loss: 0.2570 - val_accuracy: 0.9130\n",
      "Epoch 36/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.1474 - accuracy: 0.9510 - val_loss: 0.2054 - val_accuracy: 0.9565\n",
      "Epoch 37/100\n",
      "204/204 [==============================] - 1s 7ms/sample - loss: 0.1329 - accuracy: 0.9559 - val_loss: 0.4576 - val_accuracy: 0.7826\n",
      "Epoch 38/100\n",
      "204/204 [==============================] - 1s 7ms/sample - loss: 0.2400 - accuracy: 0.9069 - val_loss: 0.3956 - val_accuracy: 0.7826\n",
      "Epoch 39/100\n",
      "204/204 [==============================] - 1s 7ms/sample - loss: 0.2564 - accuracy: 0.9069 - val_loss: 0.4357 - val_accuracy: 0.7826\n",
      "Epoch 40/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.1698 - accuracy: 0.9412 - val_loss: 0.2867 - val_accuracy: 0.8261\n",
      "Epoch 41/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.1819 - accuracy: 0.9314 - val_loss: 0.1760 - val_accuracy: 0.9130\n",
      "Epoch 42/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.1978 - accuracy: 0.9118 - val_loss: 0.1673 - val_accuracy: 0.9565\n",
      "Epoch 43/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.1803 - accuracy: 0.9167 - val_loss: 0.1632 - val_accuracy: 0.9565\n",
      "Epoch 44/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.1310 - accuracy: 0.9608 - val_loss: 0.1669 - val_accuracy: 0.9565\n",
      "Epoch 45/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.1146 - accuracy: 0.9657 - val_loss: 0.1768 - val_accuracy: 0.9130\n",
      "Epoch 46/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.1262 - accuracy: 0.9608 - val_loss: 0.2104 - val_accuracy: 0.8696\n",
      "Epoch 47/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.1175 - accuracy: 0.9608 - val_loss: 0.1332 - val_accuracy: 0.9565\n",
      "Epoch 48/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.1101 - accuracy: 0.9559 - val_loss: 0.1280 - val_accuracy: 0.9565\n",
      "Epoch 49/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.0996 - accuracy: 0.9657 - val_loss: 0.1403 - val_accuracy: 0.9565\n",
      "Epoch 50/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.1088 - accuracy: 0.9706 - val_loss: 0.1170 - val_accuracy: 0.9565\n",
      "Epoch 51/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.1137 - accuracy: 0.9559 - val_loss: 0.1112 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.0827 - accuracy: 0.9608 - val_loss: 0.1578 - val_accuracy: 0.9565\n",
      "Epoch 53/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.1385 - accuracy: 0.9510 - val_loss: 0.1365 - val_accuracy: 0.9565\n",
      "Epoch 54/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.0701 - accuracy: 0.9755 - val_loss: 0.3109 - val_accuracy: 0.7826\n",
      "Epoch 55/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.1083 - accuracy: 0.9608 - val_loss: 0.2779 - val_accuracy: 0.8261\n",
      "Epoch 56/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.1659 - accuracy: 0.9265 - val_loss: 0.8044 - val_accuracy: 0.6957\n",
      "Epoch 57/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.7715 - accuracy: 0.7598 - val_loss: 1.2838 - val_accuracy: 0.3913\n",
      "Epoch 58/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.5275 - accuracy: 0.7304 - val_loss: 0.2564 - val_accuracy: 0.8696\n",
      "Epoch 59/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.2697 - accuracy: 0.8971 - val_loss: 0.3252 - val_accuracy: 0.8261\n",
      "Epoch 60/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.2267 - accuracy: 0.9216 - val_loss: 0.2690 - val_accuracy: 0.8261\n",
      "Epoch 61/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.1964 - accuracy: 0.9314 - val_loss: 0.2379 - val_accuracy: 0.9565\n",
      "Epoch 62/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.1519 - accuracy: 0.9608 - val_loss: 0.2568 - val_accuracy: 0.9130\n",
      "Epoch 63/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.1561 - accuracy: 0.9461 - val_loss: 0.2356 - val_accuracy: 0.8696\n",
      "Epoch 64/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.1219 - accuracy: 0.9608 - val_loss: 0.1729 - val_accuracy: 0.9565\n",
      "Epoch 65/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.0957 - accuracy: 0.9608 - val_loss: 0.1395 - val_accuracy: 0.9565\n",
      "Epoch 66/100\n",
      "204/204 [==============================] - 1s 7ms/sample - loss: 0.0813 - accuracy: 0.9657 - val_loss: 0.4105 - val_accuracy: 0.7391\n",
      "Epoch 67/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.1629 - accuracy: 0.9461 - val_loss: 0.3461 - val_accuracy: 0.8696\n",
      "Epoch 68/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.1130 - accuracy: 0.9608 - val_loss: 0.1283 - val_accuracy: 0.9565\n",
      "Epoch 69/100\n",
      "204/204 [==============================] - 1s 7ms/sample - loss: 0.0788 - accuracy: 0.9706 - val_loss: 0.1189 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.0700 - accuracy: 0.9755 - val_loss: 0.1782 - val_accuracy: 0.9130\n",
      "Epoch 71/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.0839 - accuracy: 0.9706 - val_loss: 0.2870 - val_accuracy: 0.8261\n",
      "Epoch 72/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.1618 - accuracy: 0.9461 - val_loss: 0.4829 - val_accuracy: 0.7826\n",
      "Epoch 73/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.2180 - accuracy: 0.9069 - val_loss: 0.1189 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.1558 - accuracy: 0.9412 - val_loss: 0.2159 - val_accuracy: 0.8696\n",
      "Epoch 75/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.0896 - accuracy: 0.9559 - val_loss: 0.1377 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.0767 - accuracy: 0.9706 - val_loss: 0.1616 - val_accuracy: 0.9130\n",
      "Epoch 77/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.0892 - accuracy: 0.9608 - val_loss: 0.3222 - val_accuracy: 0.8261\n",
      "Epoch 78/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.1008 - accuracy: 0.9657 - val_loss: 0.1291 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.0487 - accuracy: 0.9902 - val_loss: 0.1317 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "204/204 [==============================] - 1s 7ms/sample - loss: 0.0441 - accuracy: 0.9902 - val_loss: 0.1668 - val_accuracy: 0.9130\n",
      "Epoch 81/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 0.9130\n",
      "Epoch 82/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.0382 - accuracy: 0.9951 - val_loss: 0.1205 - val_accuracy: 0.9565\n",
      "Epoch 83/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.0365 - accuracy: 0.9902 - val_loss: 0.3398 - val_accuracy: 0.7826\n",
      "Epoch 84/100\n",
      "204/204 [==============================] - 1s 7ms/sample - loss: 0.0562 - accuracy: 0.9951 - val_loss: 0.1225 - val_accuracy: 0.9565\n",
      "Epoch 85/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.0360 - accuracy: 0.9902 - val_loss: 0.1252 - val_accuracy: 0.9565\n",
      "Epoch 86/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.0502 - accuracy: 0.9804 - val_loss: 0.3160 - val_accuracy: 0.8696\n",
      "Epoch 87/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.0465 - accuracy: 0.9951 - val_loss: 0.1390 - val_accuracy: 0.9130\n",
      "Epoch 88/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.1247 - val_accuracy: 0.9565\n",
      "Epoch 89/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 0.9130\n",
      "Epoch 90/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.1196 - val_accuracy: 0.9565\n",
      "Epoch 91/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.1169 - val_accuracy: 0.9565\n",
      "Epoch 92/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.2103 - val_accuracy: 0.9130\n",
      "Epoch 93/100\n",
      "204/204 [==============================] - 2s 8ms/sample - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9130\n",
      "Epoch 94/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "204/204 [==============================] - 1s 6ms/sample - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9565\n",
      "Epoch 96/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.3009 - val_accuracy: 0.9130\n",
      "Epoch 97/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.1167 - val_accuracy: 0.9130\n",
      "Epoch 98/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.1146 - val_accuracy: 0.9565\n",
      "Epoch 99/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.1576 - val_accuracy: 0.9130\n",
      "Epoch 100/100\n",
      "204/204 [==============================] - 1s 5ms/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 0.9565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21e801416a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "import pickle\n",
    "\n",
    "#Pickle - serialize machine learning algorithm and save serialize format\n",
    "\n",
    "#pickle.dump - converting python object into a character stream\n",
    "\n",
    "#rb - open for read mode and binary mode\n",
    "\n",
    "#wb -open for write mode and binary mode\n",
    "\n",
    "#dense layer - used to change dimention of the vector\n",
    "\n",
    "#dropout - ignores neurons\n",
    "\n",
    "#activation function - mathematical gate in input \n",
    "\n",
    "#Flatten - converts feature map to single column to connected layer and dense adds the fully connected layer to neural network\n",
    "\n",
    "#Numpy - array proccessing pacakge\n",
    "\n",
    "#Conv2d - 2D convolutional layer create a kernal help to produce tensor outputs\n",
    "\n",
    "#maxpooling2d - maps region of image to a feature map\n",
    "\n",
    "X = pickle.load(open(\"X.pickle\",\"rb\"))\n",
    "y = pickle.load(open(\"y.pickle\",\"rb\"))\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3,3), input_shape = X.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "y = np.array(y)\n",
    "print(X.shape, X.dtype)\n",
    "print(y.shape, y.dtype)\n",
    "model.fit(X, y, batch_size=32, epochs=100, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227, 50, 50, 3) float64\n",
      "(227,) int32\n",
      "Train on 204 samples, validate on 23 samples\n",
      "Epoch 1/100\n",
      "204/204 [==============================] - 8s 38ms/sample - loss: 0.6697 - accuracy: 0.6324 - val_loss: 0.6255 - val_accuracy: 0.6957\n",
      "Epoch 2/100\n",
      "204/204 [==============================] - 6s 27ms/sample - loss: 0.6499 - accuracy: 0.6520 - val_loss: 0.6252 - val_accuracy: 0.6957\n",
      "Epoch 3/100\n",
      "204/204 [==============================] - 7s 34ms/sample - loss: 0.6474 - accuracy: 0.6520 - val_loss: 0.6249 - val_accuracy: 0.6957\n",
      "Epoch 4/100\n",
      "204/204 [==============================] - 9s 43ms/sample - loss: 0.6429 - accuracy: 0.6569 - val_loss: 0.6245 - val_accuracy: 0.6957\n",
      "Epoch 5/100\n",
      "204/204 [==============================] - 8s 37ms/sample - loss: 0.6452 - accuracy: 0.6618 - val_loss: 0.6242 - val_accuracy: 0.6957\n",
      "Epoch 6/100\n",
      "204/204 [==============================] - 8s 40ms/sample - loss: 0.6462 - accuracy: 0.6520 - val_loss: 0.6240 - val_accuracy: 0.6957\n",
      "Epoch 7/100\n",
      "204/204 [==============================] - 9s 43ms/sample - loss: 0.6447 - accuracy: 0.6569 - val_loss: 0.6238 - val_accuracy: 0.6957\n",
      "Epoch 8/100\n",
      "204/204 [==============================] - 10s 48ms/sample - loss: 0.6508 - accuracy: 0.6471 - val_loss: 0.6237 - val_accuracy: 0.6957\n",
      "Epoch 9/100\n",
      "204/204 [==============================] - 10s 47ms/sample - loss: 0.6447 - accuracy: 0.6569 - val_loss: 0.6235 - val_accuracy: 0.6957\n",
      "Epoch 10/100\n",
      "204/204 [==============================] - 8s 39ms/sample - loss: 0.6433 - accuracy: 0.6569 - val_loss: 0.6233 - val_accuracy: 0.6957\n",
      "Epoch 11/100\n",
      "204/204 [==============================] - 7s 36ms/sample - loss: 0.6447 - accuracy: 0.6569 - val_loss: 0.6231 - val_accuracy: 0.6957\n",
      "Epoch 12/100\n",
      "204/204 [==============================] - 8s 37ms/sample - loss: 0.6442 - accuracy: 0.6520 - val_loss: 0.6228 - val_accuracy: 0.6957\n",
      "Epoch 13/100\n",
      "204/204 [==============================] - 7s 32ms/sample - loss: 0.6465 - accuracy: 0.6520 - val_loss: 0.6226 - val_accuracy: 0.6957\n",
      "Epoch 14/100\n",
      "204/204 [==============================] - 8s 40ms/sample - loss: 0.6457 - accuracy: 0.6520 - val_loss: 0.6224 - val_accuracy: 0.6957\n",
      "Epoch 15/100\n",
      "204/204 [==============================] - 8s 37ms/sample - loss: 0.6442 - accuracy: 0.6569 - val_loss: 0.6222 - val_accuracy: 0.6957\n",
      "Epoch 16/100\n",
      "204/204 [==============================] - 7s 35ms/sample - loss: 0.6445 - accuracy: 0.6569 - val_loss: 0.6221 - val_accuracy: 0.6957\n",
      "Epoch 17/100\n",
      "204/204 [==============================] - 7s 36ms/sample - loss: 0.6450 - accuracy: 0.6569 - val_loss: 0.6219 - val_accuracy: 0.6957\n",
      "Epoch 18/100\n",
      "204/204 [==============================] - 8s 39ms/sample - loss: 0.6462 - accuracy: 0.6569 - val_loss: 0.6218 - val_accuracy: 0.6957\n",
      "Epoch 19/100\n",
      "204/204 [==============================] - 7s 35ms/sample - loss: 0.6453 - accuracy: 0.6569 - val_loss: 0.6217 - val_accuracy: 0.6957\n",
      "Epoch 20/100\n",
      "204/204 [==============================] - 7s 34ms/sample - loss: 0.6428 - accuracy: 0.6569 - val_loss: 0.6216 - val_accuracy: 0.6957\n",
      "Epoch 21/100\n",
      "204/204 [==============================] - 8s 38ms/sample - loss: 0.6448 - accuracy: 0.6569 - val_loss: 0.6215 - val_accuracy: 0.6957\n",
      "Epoch 22/100\n",
      "204/204 [==============================] - 9s 43ms/sample - loss: 0.6457 - accuracy: 0.6569 - val_loss: 0.6213 - val_accuracy: 0.6957\n",
      "Epoch 23/100\n",
      "204/204 [==============================] - 8s 39ms/sample - loss: 0.6414 - accuracy: 0.6569 - val_loss: 0.6212 - val_accuracy: 0.6957\n",
      "Epoch 24/100\n",
      "204/204 [==============================] - 7s 33ms/sample - loss: 0.6444 - accuracy: 0.6569 - val_loss: 0.6211 - val_accuracy: 0.6957\n",
      "Epoch 25/100\n",
      "204/204 [==============================] - 8s 37ms/sample - loss: 0.6403 - accuracy: 0.6569 - val_loss: 0.6211 - val_accuracy: 0.6957\n",
      "Epoch 26/100\n",
      "204/204 [==============================] - 7s 33ms/sample - loss: 0.6439 - accuracy: 0.6569 - val_loss: 0.6211 - val_accuracy: 0.6957\n",
      "Epoch 27/100\n",
      "204/204 [==============================] - 7s 35ms/sample - loss: 0.6451 - accuracy: 0.6569 - val_loss: 0.6211 - val_accuracy: 0.6957\n",
      "Epoch 28/100\n",
      "204/204 [==============================] - 7s 33ms/sample - loss: 0.6431 - accuracy: 0.6569 - val_loss: 0.6210 - val_accuracy: 0.6957\n",
      "Epoch 29/100\n",
      "204/204 [==============================] - 7s 36ms/sample - loss: 0.6441 - accuracy: 0.6569 - val_loss: 0.6210 - val_accuracy: 0.6957\n",
      "Epoch 30/100\n",
      "204/204 [==============================] - 7s 34ms/sample - loss: 0.6441 - accuracy: 0.6569 - val_loss: 0.6210 - val_accuracy: 0.6957\n",
      "Epoch 31/100\n",
      "204/204 [==============================] - 7s 34ms/sample - loss: 0.6437 - accuracy: 0.6569 - val_loss: 0.6210 - val_accuracy: 0.6957\n",
      "Epoch 32/100\n",
      "204/204 [==============================] - 6s 32ms/sample - loss: 0.6438 - accuracy: 0.6569 - val_loss: 0.6213 - val_accuracy: 0.6957\n",
      "Epoch 33/100\n",
      "204/204 [==============================] - 8s 37ms/sample - loss: 0.6445 - accuracy: 0.6569 - val_loss: 0.6212 - val_accuracy: 0.6957\n",
      "Epoch 34/100\n",
      "204/204 [==============================] - 7s 34ms/sample - loss: 0.6442 - accuracy: 0.6569 - val_loss: 0.6212 - val_accuracy: 0.6957\n",
      "Epoch 35/100\n",
      "204/204 [==============================] - 7s 34ms/sample - loss: 0.6445 - accuracy: 0.6569 - val_loss: 0.6211 - val_accuracy: 0.6957\n",
      "Epoch 36/100\n",
      "204/204 [==============================] - 7s 32ms/sample - loss: 0.6445 - accuracy: 0.6569 - val_loss: 0.6210 - val_accuracy: 0.6957\n",
      "Epoch 37/100\n",
      "204/204 [==============================] - 7s 36ms/sample - loss: 0.6461 - accuracy: 0.6569 - val_loss: 0.6208 - val_accuracy: 0.6957\n",
      "Epoch 38/100\n",
      "204/204 [==============================] - 7s 34ms/sample - loss: 0.6427 - accuracy: 0.6569 - val_loss: 0.6205 - val_accuracy: 0.6957\n",
      "Epoch 39/100\n",
      "204/204 [==============================] - 7s 33ms/sample - loss: 0.6443 - accuracy: 0.6569 - val_loss: 0.6204 - val_accuracy: 0.6957\n",
      "Epoch 40/100\n",
      "204/204 [==============================] - 7s 32ms/sample - loss: 0.6454 - accuracy: 0.6569 - val_loss: 0.6202 - val_accuracy: 0.6957\n",
      "Epoch 41/100\n",
      "204/204 [==============================] - 7s 36ms/sample - loss: 0.6442 - accuracy: 0.6569 - val_loss: 0.6201 - val_accuracy: 0.6957\n",
      "Epoch 42/100\n",
      "204/204 [==============================] - 7s 34ms/sample - loss: 0.6454 - accuracy: 0.6569 - val_loss: 0.6201 - val_accuracy: 0.6957\n",
      "Epoch 43/100\n",
      "204/204 [==============================] - 7s 33ms/sample - loss: 0.6431 - accuracy: 0.6569 - val_loss: 0.6201 - val_accuracy: 0.6957\n",
      "Epoch 44/100\n",
      "204/204 [==============================] - 7s 32ms/sample - loss: 0.6417 - accuracy: 0.6569 - val_loss: 0.6201 - val_accuracy: 0.6957\n",
      "Epoch 45/100\n",
      "204/204 [==============================] - 7s 36ms/sample - loss: 0.6446 - accuracy: 0.6569 - val_loss: 0.6202 - val_accuracy: 0.6957\n",
      "Epoch 46/100\n",
      "204/204 [==============================] - 7s 34ms/sample - loss: 0.6452 - accuracy: 0.6569 - val_loss: 0.6202 - val_accuracy: 0.6957\n",
      "Epoch 47/100\n",
      "204/204 [==============================] - 7s 34ms/sample - loss: 0.6452 - accuracy: 0.6569 - val_loss: 0.6201 - val_accuracy: 0.6957\n",
      "Epoch 48/100\n",
      "204/204 [==============================] - 7s 33ms/sample - loss: 0.6461 - accuracy: 0.6569 - val_loss: 0.6201 - val_accuracy: 0.6957\n",
      "Epoch 49/100\n",
      "204/204 [==============================] - 7s 36ms/sample - loss: 0.6436 - accuracy: 0.6569 - val_loss: 0.6200 - val_accuracy: 0.6957\n",
      "Epoch 50/100\n",
      "204/204 [==============================] - 7s 35ms/sample - loss: 0.6428 - accuracy: 0.6569 - val_loss: 0.6200 - val_accuracy: 0.6957\n",
      "Epoch 51/100\n",
      "204/204 [==============================] - 7s 35ms/sample - loss: 0.6445 - accuracy: 0.6569 - val_loss: 0.6199 - val_accuracy: 0.6957\n",
      "Epoch 52/100\n",
      "204/204 [==============================] - 7s 33ms/sample - loss: 0.6439 - accuracy: 0.6569 - val_loss: 0.6197 - val_accuracy: 0.6957\n",
      "Epoch 53/100\n",
      "204/204 [==============================] - 7s 36ms/sample - loss: 0.6427 - accuracy: 0.6569 - val_loss: 0.6196 - val_accuracy: 0.6957\n",
      "Epoch 54/100\n",
      "204/204 [==============================] - 7s 35ms/sample - loss: 0.6438 - accuracy: 0.6569 - val_loss: 0.6195 - val_accuracy: 0.6957\n",
      "Epoch 55/100\n",
      "204/204 [==============================] - 7s 32ms/sample - loss: 0.6444 - accuracy: 0.6569 - val_loss: 0.6194 - val_accuracy: 0.6957\n",
      "Epoch 56/100\n",
      "204/204 [==============================] - 7s 34ms/sample - loss: 0.6433 - accuracy: 0.6569 - val_loss: 0.6194 - val_accuracy: 0.6957\n",
      "Epoch 57/100\n",
      "204/204 [==============================] - 7s 36ms/sample - loss: 0.6441 - accuracy: 0.6569 - val_loss: 0.6193 - val_accuracy: 0.6957\n",
      "Epoch 58/100\n",
      "204/204 [==============================] - 8s 40ms/sample - loss: 0.6430 - accuracy: 0.6569 - val_loss: 0.6194 - val_accuracy: 0.6957\n",
      "Epoch 59/100\n",
      "204/204 [==============================] - 8s 37ms/sample - loss: 0.6449 - accuracy: 0.6569 - val_loss: 0.6193 - val_accuracy: 0.6957\n",
      "Epoch 60/100\n",
      "204/204 [==============================] - 8s 40ms/sample - loss: 0.6425 - accuracy: 0.6569 - val_loss: 0.6193 - val_accuracy: 0.6957\n",
      "Epoch 61/100\n",
      "204/204 [==============================] - 7s 34ms/sample - loss: 0.6435 - accuracy: 0.6569 - val_loss: 0.6192 - val_accuracy: 0.6957\n",
      "Epoch 62/100\n",
      "204/204 [==============================] - 7s 35ms/sample - loss: 0.6440 - accuracy: 0.6569 - val_loss: 0.6191 - val_accuracy: 0.6957\n",
      "Epoch 63/100\n",
      "204/204 [==============================] - 7s 32ms/sample - loss: 0.6436 - accuracy: 0.6569 - val_loss: 0.6190 - val_accuracy: 0.6957\n",
      "Epoch 64/100\n",
      "204/204 [==============================] - 7s 36ms/sample - loss: 0.6418 - accuracy: 0.6569 - val_loss: 0.6189 - val_accuracy: 0.6957\n",
      "Epoch 65/100\n",
      "204/204 [==============================] - 7s 34ms/sample - loss: 0.6438 - accuracy: 0.6569 - val_loss: 0.6188 - val_accuracy: 0.6957\n",
      "Epoch 66/100\n",
      "204/204 [==============================] - 7s 35ms/sample - loss: 0.6435 - accuracy: 0.6569 - val_loss: 0.6188 - val_accuracy: 0.6957\n",
      "Epoch 67/100\n",
      "204/204 [==============================] - 8s 40ms/sample - loss: 0.6430 - accuracy: 0.6569 - val_loss: 0.6188 - val_accuracy: 0.6957\n",
      "Epoch 68/100\n",
      "204/204 [==============================] - 7s 36ms/sample - loss: 0.6426 - accuracy: 0.6569 - val_loss: 0.6189 - val_accuracy: 0.6957\n",
      "Epoch 69/100\n",
      "204/204 [==============================] - 7s 35ms/sample - loss: 0.6433 - accuracy: 0.6569 - val_loss: 0.6189 - val_accuracy: 0.6957\n",
      "Epoch 70/100\n",
      "204/204 [==============================] - 7s 33ms/sample - loss: 0.6428 - accuracy: 0.6569 - val_loss: 0.6189 - val_accuracy: 0.6957\n",
      "Epoch 71/100\n",
      "204/204 [==============================] - 7s 32ms/sample - loss: 0.6428 - accuracy: 0.6569 - val_loss: 0.6190 - val_accuracy: 0.6957\n",
      "Epoch 72/100\n",
      "204/204 [==============================] - 7s 37ms/sample - loss: 0.6439 - accuracy: 0.6569 - val_loss: 0.6190 - val_accuracy: 0.6957\n",
      "Epoch 73/100\n",
      "204/204 [==============================] - 7s 34ms/sample - loss: 0.6445 - accuracy: 0.6569 - val_loss: 0.6190 - val_accuracy: 0.6957\n",
      "Epoch 74/100\n",
      "204/204 [==============================] - 7s 33ms/sample - loss: 0.6444 - accuracy: 0.6569 - val_loss: 0.6189 - val_accuracy: 0.6957\n",
      "Epoch 75/100\n",
      "204/204 [==============================] - 7s 32ms/sample - loss: 0.6443 - accuracy: 0.6569 - val_loss: 0.6189 - val_accuracy: 0.6957\n",
      "Epoch 76/100\n",
      "204/204 [==============================] - 8s 37ms/sample - loss: 0.6430 - accuracy: 0.6569 - val_loss: 0.6188 - val_accuracy: 0.6957\n",
      "Epoch 77/100\n",
      "204/204 [==============================] - 7s 35ms/sample - loss: 0.6463 - accuracy: 0.6569 - val_loss: 0.6187 - val_accuracy: 0.6957\n",
      "Epoch 78/100\n",
      "204/204 [==============================] - 7s 35ms/sample - loss: 0.6426 - accuracy: 0.6569 - val_loss: 0.6186 - val_accuracy: 0.6957\n",
      "Epoch 79/100\n",
      "204/204 [==============================] - 7s 32ms/sample - loss: 0.6430 - accuracy: 0.6569 - val_loss: 0.6186 - val_accuracy: 0.6957\n",
      "Epoch 80/100\n",
      "204/204 [==============================] - 7s 35ms/sample - loss: 0.6438 - accuracy: 0.6569 - val_loss: 0.6185 - val_accuracy: 0.6957\n",
      "Epoch 81/100\n",
      "204/204 [==============================] - 7s 35ms/sample - loss: 0.6455 - accuracy: 0.6569 - val_loss: 0.6184 - val_accuracy: 0.6957\n",
      "Epoch 82/100\n",
      "204/204 [==============================] - 7s 34ms/sample - loss: 0.6454 - accuracy: 0.6569 - val_loss: 0.6184 - val_accuracy: 0.6957\n",
      "Epoch 83/100\n",
      "204/204 [==============================] - 7s 33ms/sample - loss: 0.6436 - accuracy: 0.6569 - val_loss: 0.6185 - val_accuracy: 0.6957\n",
      "Epoch 84/100\n",
      "204/204 [==============================] - 7s 35ms/sample - loss: 0.6428 - accuracy: 0.6569 - val_loss: 0.6185 - val_accuracy: 0.6957\n",
      "Epoch 85/100\n",
      "204/204 [==============================] - 7s 34ms/sample - loss: 0.6438 - accuracy: 0.6569 - val_loss: 0.6185 - val_accuracy: 0.6957\n",
      "Epoch 86/100\n",
      "204/204 [==============================] - 7s 35ms/sample - loss: 0.6438 - accuracy: 0.6569 - val_loss: 0.6185 - val_accuracy: 0.6957\n",
      "Epoch 87/100\n",
      "204/204 [==============================] - 7s 32ms/sample - loss: 0.6433 - accuracy: 0.6569 - val_loss: 0.6185 - val_accuracy: 0.6957\n",
      "Epoch 88/100\n",
      "204/204 [==============================] - 7s 34ms/sample - loss: 0.6462 - accuracy: 0.6569 - val_loss: 0.6186 - val_accuracy: 0.6957\n",
      "Epoch 89/100\n",
      "204/204 [==============================] - 7s 34ms/sample - loss: 0.6430 - accuracy: 0.6569 - val_loss: 0.6187 - val_accuracy: 0.6957\n",
      "Epoch 90/100\n",
      "204/204 [==============================] - 7s 36ms/sample - loss: 0.6424 - accuracy: 0.6569 - val_loss: 0.6187 - val_accuracy: 0.6957\n",
      "Epoch 91/100\n",
      "204/204 [==============================] - 8s 41ms/sample - loss: 0.6439 - accuracy: 0.6569 - val_loss: 0.6187 - val_accuracy: 0.6957\n",
      "Epoch 92/100\n",
      "204/204 [==============================] - 8s 37ms/sample - loss: 0.6442 - accuracy: 0.6569 - val_loss: 0.6186 - val_accuracy: 0.6957\n",
      "Epoch 93/100\n",
      "204/204 [==============================] - 8s 39ms/sample - loss: 0.6437 - accuracy: 0.6569 - val_loss: 0.6186 - val_accuracy: 0.6957\n",
      "Epoch 94/100\n",
      "204/204 [==============================] - 7s 35ms/sample - loss: 0.6435 - accuracy: 0.6569 - val_loss: 0.6186 - val_accuracy: 0.6957\n",
      "Epoch 95/100\n",
      "204/204 [==============================] - 8s 38ms/sample - loss: 0.6450 - accuracy: 0.6569 - val_loss: 0.6185 - val_accuracy: 0.6957\n",
      "Epoch 96/100\n",
      "204/204 [==============================] - 7s 36ms/sample - loss: 0.6458 - accuracy: 0.6569 - val_loss: 0.6185 - val_accuracy: 0.6957\n",
      "Epoch 97/100\n",
      "204/204 [==============================] - 8s 38ms/sample - loss: 0.6448 - accuracy: 0.6569 - val_loss: 0.6185 - val_accuracy: 0.6957\n",
      "Epoch 98/100\n",
      "204/204 [==============================] - 7s 35ms/sample - loss: 0.6440 - accuracy: 0.6569 - val_loss: 0.6185 - val_accuracy: 0.6957\n",
      "Epoch 99/100\n",
      "204/204 [==============================] - 8s 38ms/sample - loss: 0.6448 - accuracy: 0.6569 - val_loss: 0.6185 - val_accuracy: 0.6957\n",
      "Epoch 100/100\n",
      "204/204 [==============================] - 8s 39ms/sample - loss: 0.6427 - accuracy: 0.6569 - val_loss: 0.6185 - val_accuracy: 0.6957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21e80400cf8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'],\n",
    "              )\n",
    "\n",
    "y = np.array(y)\n",
    "print(X.shape, X.dtype)\n",
    "print(y.shape, y.dtype)\n",
    "model.fit(X, y, batch_size=62, epochs=100, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Dinara/Desktop/CNN/V2.Timber Tracker Datascience\n",
      "(227, 50, 50, 3) float64\n",
      "(227,) int32\n",
      "Train on 158 samples, validate on 69 samples\n",
      "Epoch 1/100\n",
      "158/158 [==============================] - 1s 9ms/sample - loss: 0.6805 - accuracy: 0.5253 - val_loss: 0.6747 - val_accuracy: 0.6087\n",
      "Epoch 2/100\n",
      "158/158 [==============================] - 1s 6ms/sample - loss: 0.6342 - accuracy: 0.6835 - val_loss: 0.6713 - val_accuracy: 0.6087\n",
      "Epoch 3/100\n",
      "158/158 [==============================] - 1s 6ms/sample - loss: 0.6272 - accuracy: 0.6835 - val_loss: 0.6736 - val_accuracy: 0.6087\n",
      "Epoch 4/100\n",
      "158/158 [==============================] - 1s 5ms/sample - loss: 0.6257 - accuracy: 0.6835 - val_loss: 0.6744 - val_accuracy: 0.6087\n",
      "Epoch 5/100\n",
      "158/158 [==============================] - 1s 6ms/sample - loss: 0.6259 - accuracy: 0.6835 - val_loss: 0.6748 - val_accuracy: 0.6087\n",
      "Epoch 6/100\n",
      "158/158 [==============================] - 1s 6ms/sample - loss: 0.6257 - accuracy: 0.6835 - val_loss: 0.6750 - val_accuracy: 0.6087\n",
      "Epoch 7/100\n",
      "158/158 [==============================] - 1s 6ms/sample - loss: 0.6254 - accuracy: 0.6835 - val_loss: 0.6751 - val_accuracy: 0.6087\n",
      "Epoch 8/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6254 - accuracy: 0.6835 - val_loss: 0.6753 - val_accuracy: 0.6087\n",
      "Epoch 9/100\n",
      "158/158 [==============================] - 1s 8ms/sample - loss: 0.6253 - accuracy: 0.6835 - val_loss: 0.6754 - val_accuracy: 0.6087\n",
      "Epoch 10/100\n",
      "158/158 [==============================] - 1s 8ms/sample - loss: 0.6252 - accuracy: 0.6835 - val_loss: 0.6755 - val_accuracy: 0.6087\n",
      "Epoch 11/100\n",
      "158/158 [==============================] - 1s 8ms/sample - loss: 0.6252 - accuracy: 0.6835 - val_loss: 0.6756 - val_accuracy: 0.6087\n",
      "Epoch 12/100\n",
      "158/158 [==============================] - 1s 8ms/sample - loss: 0.6252 - accuracy: 0.6835 - val_loss: 0.6758 - val_accuracy: 0.6087\n",
      "Epoch 13/100\n",
      "158/158 [==============================] - 1s 9ms/sample - loss: 0.6251 - accuracy: 0.6835 - val_loss: 0.6759 - val_accuracy: 0.6087\n",
      "Epoch 14/100\n",
      "158/158 [==============================] - 1s 8ms/sample - loss: 0.6251 - accuracy: 0.6835 - val_loss: 0.6760 - val_accuracy: 0.6087\n",
      "Epoch 15/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6251 - accuracy: 0.6835 - val_loss: 0.6762 - val_accuracy: 0.6087\n",
      "Epoch 16/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6250 - accuracy: 0.6835 - val_loss: 0.6763 - val_accuracy: 0.6087\n",
      "Epoch 17/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6249 - accuracy: 0.6835 - val_loss: 0.6764 - val_accuracy: 0.6087\n",
      "Epoch 18/100\n",
      "158/158 [==============================] - 1s 8ms/sample - loss: 0.6249 - accuracy: 0.6835 - val_loss: 0.6764 - val_accuracy: 0.6087\n",
      "Epoch 19/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6249 - accuracy: 0.6835 - val_loss: 0.6765 - val_accuracy: 0.6087\n",
      "Epoch 20/100\n",
      "158/158 [==============================] - 1s 8ms/sample - loss: 0.6248 - accuracy: 0.6835 - val_loss: 0.6766 - val_accuracy: 0.6087\n",
      "Epoch 21/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6248 - accuracy: 0.6835 - val_loss: 0.6767 - val_accuracy: 0.6087\n",
      "Epoch 22/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6248 - accuracy: 0.6835 - val_loss: 0.6769 - val_accuracy: 0.6087\n",
      "Epoch 23/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6248 - accuracy: 0.6835 - val_loss: 0.6770 - val_accuracy: 0.6087\n",
      "Epoch 24/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6247 - accuracy: 0.6835 - val_loss: 0.6771 - val_accuracy: 0.6087\n",
      "Epoch 25/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6247 - accuracy: 0.6835 - val_loss: 0.6772 - val_accuracy: 0.6087\n",
      "Epoch 26/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6247 - accuracy: 0.6835 - val_loss: 0.6774 - val_accuracy: 0.6087\n",
      "Epoch 27/100\n",
      "158/158 [==============================] - 1s 8ms/sample - loss: 0.6246 - accuracy: 0.6835 - val_loss: 0.6775 - val_accuracy: 0.6087\n",
      "Epoch 28/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6246 - accuracy: 0.6835 - val_loss: 0.6776 - val_accuracy: 0.6087\n",
      "Epoch 29/100\n",
      "158/158 [==============================] - 1s 8ms/sample - loss: 0.6246 - accuracy: 0.6835 - val_loss: 0.6777 - val_accuracy: 0.6087\n",
      "Epoch 30/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6246 - accuracy: 0.6835 - val_loss: 0.6778 - val_accuracy: 0.6087\n",
      "Epoch 31/100\n",
      "158/158 [==============================] - 1s 9ms/sample - loss: 0.6245 - accuracy: 0.6835 - val_loss: 0.6779 - val_accuracy: 0.6087\n",
      "Epoch 32/100\n",
      "158/158 [==============================] - 1s 8ms/sample - loss: 0.6245 - accuracy: 0.6835 - val_loss: 0.6781 - val_accuracy: 0.6087\n",
      "Epoch 33/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6245 - accuracy: 0.6835 - val_loss: 0.6781 - val_accuracy: 0.6087\n",
      "Epoch 34/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6245 - accuracy: 0.6835 - val_loss: 0.6783 - val_accuracy: 0.6087\n",
      "Epoch 35/100\n",
      "158/158 [==============================] - 1s 8ms/sample - loss: 0.6244 - accuracy: 0.6835 - val_loss: 0.6784 - val_accuracy: 0.6087\n",
      "Epoch 36/100\n",
      "158/158 [==============================] - 1s 8ms/sample - loss: 0.6244 - accuracy: 0.6835 - val_loss: 0.6785 - val_accuracy: 0.6087\n",
      "Epoch 37/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6244 - accuracy: 0.6835 - val_loss: 0.6786 - val_accuracy: 0.6087\n",
      "Epoch 38/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6244 - accuracy: 0.6835 - val_loss: 0.6787 - val_accuracy: 0.6087\n",
      "Epoch 39/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6244 - accuracy: 0.6835 - val_loss: 0.6787 - val_accuracy: 0.6087\n",
      "Epoch 40/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6244 - accuracy: 0.6835 - val_loss: 0.6788 - val_accuracy: 0.6087\n",
      "Epoch 41/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6244 - accuracy: 0.6835 - val_loss: 0.6789 - val_accuracy: 0.6087\n",
      "Epoch 42/100\n",
      "158/158 [==============================] - 1s 8ms/sample - loss: 0.6244 - accuracy: 0.6835 - val_loss: 0.6790 - val_accuracy: 0.6087\n",
      "Epoch 43/100\n",
      "158/158 [==============================] - 1s 8ms/sample - loss: 0.6243 - accuracy: 0.6835 - val_loss: 0.6791 - val_accuracy: 0.6087\n",
      "Epoch 44/100\n",
      "158/158 [==============================] - 1s 8ms/sample - loss: 0.6243 - accuracy: 0.6835 - val_loss: 0.6792 - val_accuracy: 0.6087\n",
      "Epoch 45/100\n",
      "158/158 [==============================] - 1s 9ms/sample - loss: 0.6243 - accuracy: 0.6835 - val_loss: 0.6793 - val_accuracy: 0.6087\n",
      "Epoch 46/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6243 - accuracy: 0.6835 - val_loss: 0.6793 - val_accuracy: 0.6087\n",
      "Epoch 47/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6243 - accuracy: 0.6835 - val_loss: 0.6794 - val_accuracy: 0.6087\n",
      "Epoch 48/100\n",
      "158/158 [==============================] - 1s 6ms/sample - loss: 0.6243 - accuracy: 0.6835 - val_loss: 0.6795 - val_accuracy: 0.6087\n",
      "Epoch 49/100\n",
      "158/158 [==============================] - 1s 6ms/sample - loss: 0.6243 - accuracy: 0.6835 - val_loss: 0.6796 - val_accuracy: 0.6087\n",
      "Epoch 50/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6243 - accuracy: 0.6835 - val_loss: 0.6796 - val_accuracy: 0.6087\n",
      "Epoch 51/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6243 - accuracy: 0.6835 - val_loss: 0.6796 - val_accuracy: 0.6087\n",
      "Epoch 52/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6243 - accuracy: 0.6835 - val_loss: 0.6797 - val_accuracy: 0.6087\n",
      "Epoch 53/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6243 - accuracy: 0.6835 - val_loss: 0.6797 - val_accuracy: 0.6087\n",
      "Epoch 54/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6243 - accuracy: 0.6835 - val_loss: 0.6798 - val_accuracy: 0.6087\n",
      "Epoch 55/100\n",
      "158/158 [==============================] - 1s 8ms/sample - loss: 0.6243 - accuracy: 0.6835 - val_loss: 0.6798 - val_accuracy: 0.6087\n",
      "Epoch 56/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6243 - accuracy: 0.6835 - val_loss: 0.6799 - val_accuracy: 0.6087\n",
      "Epoch 57/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6243 - accuracy: 0.6835 - val_loss: 0.6799 - val_accuracy: 0.6087\n",
      "Epoch 58/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6800 - val_accuracy: 0.6087\n",
      "Epoch 59/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6800 - val_accuracy: 0.6087\n",
      "Epoch 60/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6801 - val_accuracy: 0.6087\n",
      "Epoch 61/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6802 - val_accuracy: 0.6087\n",
      "Epoch 62/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6802 - val_accuracy: 0.6087\n",
      "Epoch 63/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6802 - val_accuracy: 0.6087\n",
      "Epoch 64/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6803 - val_accuracy: 0.6087\n",
      "Epoch 65/100\n",
      "158/158 [==============================] - 1s 8ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6803 - val_accuracy: 0.6087\n",
      "Epoch 66/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6804 - val_accuracy: 0.6087\n",
      "Epoch 67/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6803 - val_accuracy: 0.6087\n",
      "Epoch 68/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6803 - val_accuracy: 0.6087\n",
      "Epoch 69/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6803 - val_accuracy: 0.6087\n",
      "Epoch 70/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6803 - val_accuracy: 0.6087\n",
      "Epoch 71/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6803 - val_accuracy: 0.6087\n",
      "Epoch 72/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6804 - val_accuracy: 0.6087\n",
      "Epoch 73/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6804 - val_accuracy: 0.6087\n",
      "Epoch 74/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6805 - val_accuracy: 0.6087\n",
      "Epoch 75/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6806 - val_accuracy: 0.6087\n",
      "Epoch 76/100\n",
      "158/158 [==============================] - 1s 6ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6806 - val_accuracy: 0.6087\n",
      "Epoch 77/100\n",
      "158/158 [==============================] - 1s 6ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6807 - val_accuracy: 0.6087\n",
      "Epoch 78/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6808 - val_accuracy: 0.6087\n",
      "Epoch 79/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6808 - val_accuracy: 0.6087\n",
      "Epoch 80/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6808 - val_accuracy: 0.6087\n",
      "Epoch 81/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6808 - val_accuracy: 0.6087\n",
      "Epoch 82/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6807 - val_accuracy: 0.6087\n",
      "Epoch 83/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6807 - val_accuracy: 0.6087\n",
      "Epoch 84/100\n",
      "158/158 [==============================] - 1s 8ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6808 - val_accuracy: 0.6087\n",
      "Epoch 85/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6808 - val_accuracy: 0.6087\n",
      "Epoch 86/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6807 - val_accuracy: 0.6087\n",
      "Epoch 87/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6807 - val_accuracy: 0.6087\n",
      "Epoch 88/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6807 - val_accuracy: 0.6087\n",
      "Epoch 89/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6807 - val_accuracy: 0.6087\n",
      "Epoch 90/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6807 - val_accuracy: 0.6087\n",
      "Epoch 91/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6807 - val_accuracy: 0.6087\n",
      "Epoch 92/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6808 - val_accuracy: 0.6087\n",
      "Epoch 93/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6808 - val_accuracy: 0.6087\n",
      "Epoch 94/100\n",
      "158/158 [==============================] - 1s 8ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6808 - val_accuracy: 0.6087\n",
      "Epoch 95/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6808 - val_accuracy: 0.6087\n",
      "Epoch 96/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6808 - val_accuracy: 0.6087\n",
      "Epoch 97/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6809 - val_accuracy: 0.6087\n",
      "Epoch 98/100\n",
      "158/158 [==============================] - 1s 6ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6809 - val_accuracy: 0.6087\n",
      "Epoch 99/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6809 - val_accuracy: 0.6087\n",
      "Epoch 100/100\n",
      "158/158 [==============================] - 1s 7ms/sample - loss: 0.6242 - accuracy: 0.6835 - val_loss: 0.6809 - val_accuracy: 0.6087\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "dense_layers = [0]\n",
    "layer_sizes = [64]\n",
    "conv_layers = [3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"C:/Users/Dinara/Desktop/CNN/V2.Timber Tracker Datascience\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(NAME)\n",
    "\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3, 3), input_shape=X.shape[1:]))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "            model.add(Dropout(0.25))\n",
    "\n",
    "            for l in range(conv_layer-1):\n",
    "                model.add(Conv2D(layer_size, (3, 3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "                model.add(Dropout(0.25))\n",
    "\n",
    "            model.add(Flatten())\n",
    "\n",
    "            for _ in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(Dropout(0.5))\n",
    "\n",
    "            model.add(Dense(10, activation=\"softmax\"))\n",
    "            model.add(Dense(1))\n",
    "            model.add(Activation('sigmoid'))\n",
    "\n",
    "            tensorboard = TensorBoard(log_dir=\"logs\\\\model\\\\\".format(NAME))\n",
    "\n",
    "            model.compile(loss='binary_crossentropy',\n",
    "                          optimizer='adam',\n",
    "                          metrics=['accuracy'],\n",
    "                          )\n",
    "\n",
    "            y = np.array(y)\n",
    "            print(X.shape, X.dtype)\n",
    "            print(y.shape, y.dtype)\n",
    "            \n",
    "            model.fit(X, y,\n",
    "                      batch_size=62,\n",
    "                      epochs=100,\n",
    "                      validation_split=0.3,\n",
    "                      callbacks=[tensorboard])\n",
    "\n",
    "# Save neural network structure\n",
    "model_structure = model.to_json()\n",
    "f = Path(\"model_structure.json\")\n",
    "f.write_text(model_structure)\n",
    "\n",
    "# Save neural network's trained weights\n",
    "model.save_weights(\"model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "CATEGORIES = [\"Kohomba\", \"Mahogani\"]\n",
    "\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 50\n",
    "    img_array = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "model = tf.keras.models.load_model(\"64x3-CNN.model\")\n",
    "\n",
    "prediction = model.predict([prepare('C:/Users/Dinara/Desktop/V2.Timber Tracker Datascience/Predicting Images/kohomba.bmp')])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is image is a Kohomba - Likelihood: 0.680965\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "class_labels = [\n",
    "    \"Kohomba\",\n",
    "    \"Mahogani\"\n",
    "]\n",
    "\n",
    "# Load the json file that contains the model's structure\n",
    "f = Path(\"model_structure.json\")\n",
    "model_structure = f.read_text()\n",
    "\n",
    "# Recreate the Keras model object from the json data\n",
    "model = model_from_json(model_structure)\n",
    "\n",
    "# Re-load the model's trained weights\n",
    "model.load_weights(\"model_weights.h5\")\n",
    "\n",
    "# Load an image file to test, resizing it to 32x32 pixels (as required by this model)\n",
    "img = image.load_img(\"C:/Users/Dinara/Desktop/CNN/V2.Timber Tracker Datascience/Predicting Images/k1.bmp\", target_size=(50, 50, 3))\n",
    "\n",
    "image_to_test = image.img_to_array(img)\n",
    "\n",
    "# Add a fourth dimension to the image \n",
    "list_of_images = np.expand_dims(image_to_test, axis=0)\n",
    "\n",
    "# Make a prediction using the model\n",
    "results = model.predict(list_of_images)\n",
    "single_result = results[0]\n",
    "\n",
    "most_likely_class_index = int(np.argmax(single_result))\n",
    "class_likelihood = single_result[most_likely_class_index]\n",
    "\n",
    "# Get the name of the most likely class\n",
    "class_label = class_labels[most_likely_class_index]\n",
    "\n",
    "# Print the result\n",
    "print(\"This is image is a {} - Likelihood: {:2f}\".format(class_label, class_likelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
